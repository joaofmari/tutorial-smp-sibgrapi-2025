{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a49ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import pandas as pd\n",
    "\n",
    "models = [\n",
    "    smp.Unet,\n",
    "    smp.UnetPlusPlus,\n",
    "    smp.MAnet,\n",
    "    smp.Linknet,\n",
    "    smp.FPN,\n",
    "    smp.PSPNet,\n",
    "    smp.PAN,\n",
    "    smp.DeepLabV3,\n",
    "    smp.DeepLabV3Plus,\n",
    "]\n",
    "\n",
    "all_encoders = smp.encoders.encoders.keys()\n",
    "# Do not include timm encoders for now...\n",
    "timm_encoders = {e for e in all_encoders if 'timm' in e}\n",
    "native_encoders = sorted(set(all_encoders) - timm_encoders)\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_class in models:\n",
    "    model_name = model_class.__name__\n",
    "    for encoder_name in native_encoders:\n",
    "        try:\n",
    "            pretrained_options = smp.encoders.encoders[encoder_name]['pretrained_settings'].keys()\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"Encoder\": encoder_name,\n",
    "                \"Weights\": pretrained,\n",
    "                \"Preprocessing_fn or Error\": f\"DOWNLOAD ERROR: {str(e)}\"\n",
    "            })\n",
    "        for pretrained in pretrained_options:\n",
    "            try:\n",
    "                model = model_class(\n",
    "                    encoder_name=encoder_name,\n",
    "                    encoder_weights=pretrained,\n",
    "                    in_channels=3,\n",
    "                    classes=1\n",
    "                )\n",
    "                preprocessing_fn = get_preprocessing_fn(encoder_name, pretrained)\n",
    "                results.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Encoder\": encoder_name,\n",
    "                    \"Weights\": pretrained,\n",
    "                    \"Preprocessing_fn or Error\": preprocessing_fn.__name__ if hasattr(preprocessing_fn, '__name__') else str(preprocessing_fn)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Model\": model_name,\n",
    "                    \"Encoder\": encoder_name,\n",
    "                    \"Weights\": pretrained,\n",
    "                    \"Preprocessing_fn or Error\": f\"ERROR: {str(e)}\"\n",
    "                })\n",
    "\n",
    "results.append({\n",
    "    \"Model\": 'FINISHED!',\n",
    "    \"Encoder\": \"\",\n",
    "    \"Weights\": \"\",\n",
    "    \"Preprocessing_fn or Error\": \"\"\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"smp_model_encoder_compatibility.csv\", index=False)\n",
    "\n",
    "print('Finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-smp-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
